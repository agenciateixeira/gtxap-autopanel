// src/lib/gemini.js
import { GoogleGenerativeAI } from '@google/generative-ai'

// Usar apenas a vari√°vel do servidor
const apiKey = process.env.GEMINI_API_KEY

if (!apiKey) {
  console.warn('AVISO: GEMINI_API_KEY n√£o encontrada nas vari√°veis de ambiente.')
}

const genAI = new GoogleGenerativeAI(apiKey)

// Configura√ß√µes otimizadas
const DEFAULT_CONFIG = {
  temperature: 0.3,
  topP: 0.8,
  topK: 40,
  maxOutputTokens: 800, // Reduzido para evitar timeouts
}

// Modelo correto
export const geminiModel = genAI.getGenerativeModel({ 
  model: 'gemini-1.5-flash', // Corrigido o nome do modelo
  generationConfig: DEFAULT_CONFIG
})

// Fun√ß√£o otimizada para gerar respostas
export const generateResponse = async (prompt, context = {}, config = {}) => {
  try {
    if (!apiKey) {
      throw new Error('GEMINI_API_KEY n√£o configurada')
    }

    const finalConfig = { ...DEFAULT_CONFIG, ...config }
    const model = genAI.getGenerativeModel({ 
      model: 'gemini-1.5-flash',
      generationConfig: finalConfig
    })

    // Limitar tamanho do prompt
    let fullPrompt = prompt
    if (context && Object.keys(context).length > 0) {
      const contextStr = JSON.stringify(context, null, 2)
      if (contextStr.length > 5000) {
        // Truncar contexto muito grande
        fullPrompt = `${prompt}\n\nContexto (resumido): ${contextStr.substring(0, 5000)}...`
      } else {
        fullPrompt = `${prompt}\n\nContexto:\n${contextStr}`
      }
    }

    console.log('üì§ Enviando para Gemini:', { 
      promptLength: fullPrompt.length,
      model: 'gemini-1.5-flash'
    })
    
    const result = await model.generateContent(fullPrompt)
    const response = await result.response
    const text = response.text()
    
    console.log('üì• Resposta do Gemini:', { responseLength: text.length })
    
    return text

  } catch (error) {
    console.error('‚ùå Erro no Gemini:', error)
    
    // Tratamento espec√≠fico melhorado
    if (error.message?.includes('API_KEY_INVALID') || error.message?.includes('invalid API key')) {
      throw new Error('Chave da API do Gemini inv√°lida')
    }
    
    if (error.message?.includes('QUOTA_EXCEEDED') || error.message?.includes('quota')) {
      throw new Error('Cota da API do Gemini excedida')
    }
    
    if (error.message?.includes('BLOCKED') || error.message?.includes('safety')) {
      throw new Error('Conte√∫do bloqueado pelo filtro de seguran√ßa')
    }
    
    if (error.message?.includes('RECITATION')) {
      throw new Error('Poss√≠vel viola√ß√£o de direitos autorais detectada')
    }

    if (error.message?.includes('timeout') || error.message?.includes('TIMEOUT')) {
      throw new Error('Timeout na API do Gemini - tente novamente')
    }
    
    // Erro gen√©rico com mais detalhes
    throw new Error(`Erro na IA: ${error.message || 'Erro desconhecido'}`)
  }
}

// Teste de conex√£o melhorado
export const testConnection = async () => {
  try {
    const response = await generateResponse('Responda apenas: OK', {}, { maxOutputTokens: 10 })
    return response.toLowerCase().includes('ok')
  } catch (error) {
    console.error('‚ùå Teste de conex√£o falhou:', error)
    return false
  }
}

export { genAI }